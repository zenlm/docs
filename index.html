<!DOCTYPE html><!--2ezz_PBbsRcymwbmfjjIq--><html lang="en"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="stylesheet" href="/_next/static/css/1d1f6bc532e5f43f.css" data-precedence="next"/><link rel="preload" as="script" fetchPriority="low" href="/_next/static/chunks/webpack-2eb758dea75faf50.js"/><script src="/_next/static/chunks/4bd1b696-c023c6e3521b1417.js" async=""></script><script src="/_next/static/chunks/255-bc8b3b9a93d25a64.js" async=""></script><script src="/_next/static/chunks/main-app-06c948c55f93babd.js" async=""></script><script src="/_next/static/chunks/619-ba102abea3e3d0e4.js" async=""></script><script src="/_next/static/chunks/394-7ae625d7fca91f5c.js" async=""></script><script src="/_next/static/chunks/app/layout-69b551721b5ae1f6.js" async=""></script><script src="/_next/static/chunks/app/page-6f8a3b3ea33cc66d.js" async=""></script><script src="/assets/js/main.js" async=""></script><link rel="icon" type="image/png" href="/favicon.png"/><title>Zen LM - Open Foundation Models for Agentic AI</title><meta name="description" content="30+ open models from 0.6B to 1T parameters. Flagship Zen Coder trained on 8.47B tokens of real programming sessions."/><meta name="keywords" content="AI, LLM, Agentic AI, Code Generation, Zen Coder, Multimodal, Open Source, Machine Learning"/><script src="/_next/static/chunks/polyfills-42372ed130431b0a.js" noModule=""></script></head><body><div hidden=""><!--$--><!--/$--></div><header><nav class="navbar"><div class="container"><div class="logo"><a href="/"><img alt="Zen LM" loading="lazy" width="50" height="50" decoding="async" data-nimg="1" class="logo-img" style="color:transparent" src="/logo.png"/><div class="logo-text"><h1>Zen LM</h1></div></a></div><div class="header-right"><div class="nav-links"><a class="active" href="/">Home</a><a class="" href="/models/">Models</a><a class="" href="/datasets/">Datasets</a><a class="" href="/research/">Research</a></div><div class="logo-links"><a href="https://github.com/zenlm" target="_blank" rel="noopener noreferrer" class="icon-link" title="GitHub"><svg width="24" height="24" viewBox="0 0 24 24" fill="currentColor"><path d="M12 0c-6.626 0-12 5.373-12 12 0 5.302 3.438 9.8 8.207 11.387.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23.957-.266 1.983-.399 3.003-.404 1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576 4.765-1.589 8.199-6.086 8.199-11.386 0-6.627-5.373-12-12-12z"></path></svg></a><a href="https://huggingface.co/zenlm" target="_blank" rel="noopener noreferrer" class="icon-link" title="HuggingFace"><img alt="HuggingFace" loading="lazy" width="28" height="28" decoding="async" data-nimg="1" style="color:transparent" src="/hf-logo.png"/></a></div></div></div></nav></header><main><section class="hero"><div class="container"><h2 class="hero-title">Open Foundation Models for Agentic AI</h2><p class="hero-subtitle">30+ models from 0.6B to 1T parameters across language, vision, audio, video, and 3D</p><p class="hero-description">Zen LM provides production-ready AI models for agentic coding, multimodal understanding, and creative generation. Our flagship Zen Coder models are trained on 8.47 billion tokens of real-world programming sessions, delivering state-of-the-art performance on agentic programming tasks.</p><div class="hero-cta"><a class="btn btn-primary" href="/models/">Explore Models</a><a class="btn btn-secondary" href="/datasets/">Training Data</a><a class="btn btn-outline" href="/research/">Research Papers</a></div></div></section><section id="zen-coder" class="featured-section"><div class="container"><h2 class="section-title">Zen Coder - Agentic Coding Models</h2><p class="section-subtitle">Fine-tuned on 8.47B tokens of real programming sessions</p><div class="model-lineup"><table class="models-table"><thead><tr><th>Model</th><th>Size</th><th>Base</th><th>VRAM</th><th>Context</th><th>Status</th></tr></thead><tbody><tr><td><strong>Zen Coder 4B</strong></td><td>4B</td><td>Qwen3-4B-Instruct</td><td>8 GB</td><td>32K</td><td><span class="status-trained">Trained</span></td></tr><tr><td><strong>Zen Coder 24B</strong></td><td>24B</td><td>Devstral Small 2</td><td>24 GB</td><td>256K</td><td><span class="status-trained">Trained</span></td></tr><tr><td><strong>Zen Coder 123B</strong></td><td>123B</td><td>Devstral 2</td><td>128 GB</td><td>256K</td><td><span class="status-training">Training</span></td></tr><tr><td><strong>Zen Coder Max</strong></td><td>358B</td><td>GLM-4.7 (MoE)</td><td>180 GB</td><td>200K</td><td><span class="status-planned">Planned</span></td></tr><tr><td><strong>Zen Coder Ultra</strong></td><td>1T</td><td>Kimi K2 (MoE)</td><td>256 GB</td><td>128K</td><td><span class="status-planned">Planned</span></td></tr></tbody></table></div><div class="coder-features arch-grid"><div class="arch-card"><h3>Real Agentic Data</h3><p>Trained on actual agentic debug sessions - not synthetic data. Real debugging workflows, multi-file refactoring, and tool use patterns.</p></div><div class="arch-card"><h3>Production Code</h3><p>15 years of professional development across AI, Web3, cryptography, and modern software engineering from 1,452 repositories.</p></div><div class="arch-card"><h3>Open Training</h3><p>Use <a href="https://github.com/zenlm/zen-trainer">zen-trainer</a> to fine-tune on your own data. Supports MLX (Apple Silicon), Unsloth, and DeepSpeed.</p></div></div></div></section><section id="overview" class="architecture-section"><div class="container"><h2 class="section-title">Complete AI Model Ecosystem</h2><div class="arch-grid"><div class="arch-card"><div class="arch-icon">üß†</div><h3>Language Models</h3><p>6 core models from 0.6B to 32B. zen-nano for edge, zen-eco for efficiency, zen-omni for multimodal, zen-next for frontier reasoning.</p></div><div class="arch-card"><div class="arch-icon">üíª</div><h3>Zen Coder</h3><p>5 coding models from 4B to 1T trained on 8.47B tokens of agentic programming data. State-of-the-art on tool use and multi-step coding.</p></div><div class="arch-card"><div class="arch-icon">üëÅÔ∏è</div><h3>Vision &amp; Multimodal</h3><p>zen-vl for vision-language, zen-designer for visual understanding, zen-artist for image generation, zen-omni for unified multimodal.</p></div><div class="arch-card"><div class="arch-icon">üé¨</div><h3>Video &amp; 3D</h3><p>zen-director for video generation, zen-video for high-quality synthesis, zen-3d for 3D assets, zen-world for world simulation.</p></div><div class="arch-card"><div class="arch-icon">üéµ</div><h3>Audio</h3><p>zen-musician for music generation, zen-foley for sound effects, zen-scribe for transcription, zen-dub for voice dubbing.</p></div><div class="arch-card"><div class="arch-icon">üõ°Ô∏è</div><h3>Specialized</h3><p>zen-guard for safety, zen-embedding for vectors, zen-reranker for search, zen-translator for translation, zen-agent for tool use.</p></div></div></div></section><section id="dataset" class="dataset-section"><div class="container"><h2 class="section-title">Zen Agentic Dataset</h2><p class="section-subtitle">8.47 Billion Tokens of Real-World Agentic Programming</p><div class="arch-grid"><div class="arch-card"><div class="arch-icon">8.47B</div><h3>Tokens</h3><p>Total training tokens across all data sources</p></div><div class="arch-card"><div class="arch-icon">3.35M</div><h3>Samples</h3><p>Training samples with conversation context</p></div><div class="arch-card"><div class="arch-icon">1,452</div><h3>Repositories</h3><p>Open source and private codebases</p></div><div class="arch-card"><div class="arch-icon">15yr</div><h3>History</h3><p>Years of development history (2010-2025)</p></div></div><div class="dataset-cta" style="text-align:center;margin-top:2rem"><p>Available for research and commercial licensing.</p><a href="mailto:z@hanzo.ai" class="btn btn-primary">Request Access</a><a href="https://huggingface.co/datasets/hanzoai/zen-agentic-dataset" class="btn btn-secondary" target="_blank" rel="noopener noreferrer">View on HuggingFace</a></div></div></section><section id="downloads" class="downloads-section"><div class="container"><h2 class="section-title">Get Started</h2><div class="download-grid"><div class="download-card"><h3>HuggingFace</h3><p>Access all 30+ models via HuggingFace Hub</p><a href="https://huggingface.co/zenlm" class="btn btn-primary" target="_blank" rel="noopener noreferrer">Visit HuggingFace</a></div><div class="download-card"><h3>GitHub</h3><p>Training code, documentation, and source</p><a href="https://github.com/zenlm" class="btn btn-primary" target="_blank" rel="noopener noreferrer">View on GitHub</a></div><div class="download-card"><h3>zen-trainer</h3><p>Fine-tune models on your own data</p><pre><code>pip install zen-trainer</code></pre></div><div class="download-card"><h3>Research</h3><p>Technical papers and whitepapers</p><a class="btn btn-primary" href="/research/">Read Papers</a></div></div></div></section></main><!--$--><!--/$--><footer><div class="container"><div class="footer-content"><div class="footer-section"><h4>Zen LM</h4><p>Open foundation models for agentic AI. 30+ models from 0.6B to 1T parameters.</p></div><div class="footer-section"><h4>Zen Coder</h4><ul><li><a href="/models/#zen-coder">Zen Coder 4B</a></li><li><a href="/models/#zen-coder">Zen Coder 24B</a></li><li><a href="/models/#zen-coder">Zen Coder 123B</a></li><li><a href="/models/#zen-coder">Zen Coder Max (358B)</a></li><li><a href="/models/#zen-coder">Zen Coder Ultra (1T)</a></li></ul></div><div class="footer-section"><h4>Model Family</h4><ul><li><a href="/models/#core-models">zen-nano (0.6B)</a></li><li><a href="/models/#core-models">zen-eco (4B)</a></li><li><a href="/models/#core-models">zen-omni (7B)</a></li><li><a href="/models/#multimodal">zen-vl (Vision)</a></li><li><a href="/models/#multimodal">zen-3d (3D Gen)</a></li></ul></div><div class="footer-section"><h4>Resources</h4><ul><li><a href="/datasets/">Training Data</a></li><li><a href="https://huggingface.co/zenlm" target="_blank" rel="noopener noreferrer">HuggingFace</a></li><li><a href="https://github.com/zenlm" target="_blank" rel="noopener noreferrer">GitHub</a></li><li><a href="/research/">Research Papers</a></li><li><a href="https://github.com/zenlm/zen-trainer" target="_blank" rel="noopener noreferrer">zen-trainer</a></li></ul></div></div><div class="footer-bottom"><p>¬© 2025 Zen Authors. All rights reserved. Built with clarity and purpose.</p></div></div></footer><script src="/_next/static/chunks/webpack-2eb758dea75faf50.js" id="_R_" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0])</script><script>self.__next_f.push([1,"1:\"$Sreact.fragment\"\n2:I[1398,[\"619\",\"static/chunks/619-ba102abea3e3d0e4.js\",\"394\",\"static/chunks/394-7ae625d7fca91f5c.js\",\"177\",\"static/chunks/app/layout-69b551721b5ae1f6.js\"],\"default\"]\n3:I[9766,[],\"\"]\n4:I[8924,[],\"\"]\n5:I[2619,[\"619\",\"static/chunks/619-ba102abea3e3d0e4.js\",\"974\",\"static/chunks/app/page-6f8a3b3ea33cc66d.js\"],\"\"]\ne:I[7150,[],\"\"]\n:HL[\"/_next/static/css/1d1f6bc532e5f43f.css\",\"style\"]\n"])</script><script>self.__next_f.push([1,"0:{\"P\":null,\"b\":\"2ezz-PBbsRcymwbmfjjIq\",\"p\":\"\",\"c\":[\"\",\"\"],\"i\":false,\"f\":[[[\"\",{\"children\":[\"__PAGE__\",{}]},\"$undefined\",\"$undefined\",true],[\"\",[\"$\",\"$1\",\"c\",{\"children\":[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/1d1f6bc532e5f43f.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}]],[\"$\",\"html\",null,{\"lang\":\"en\",\"children\":[[\"$\",\"head\",null,{\"children\":[\"$\",\"link\",null,{\"rel\":\"icon\",\"type\":\"image/png\",\"href\":\"/favicon.png\"}]}],[\"$\",\"body\",null,{\"children\":[[\"$\",\"$L2\",null,{}],[\"$\",\"$L3\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L4\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[[[\"$\",\"title\",null,{\"children\":\"404: This page could not be found.\"}],[\"$\",\"div\",null,{\"style\":{\"fontFamily\":\"system-ui,\\\"Segoe UI\\\",Roboto,Helvetica,Arial,sans-serif,\\\"Apple Color Emoji\\\",\\\"Segoe UI Emoji\\\"\",\"height\":\"100vh\",\"textAlign\":\"center\",\"display\":\"flex\",\"flexDirection\":\"column\",\"alignItems\":\"center\",\"justifyContent\":\"center\"},\"children\":[\"$\",\"div\",null,{\"children\":[[\"$\",\"style\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}\"}}],[\"$\",\"h1\",null,{\"className\":\"next-error-h1\",\"style\":{\"display\":\"inline-block\",\"margin\":\"0 20px 0 0\",\"padding\":\"0 23px 0 0\",\"fontSize\":24,\"fontWeight\":500,\"verticalAlign\":\"top\",\"lineHeight\":\"49px\"},\"children\":404}],[\"$\",\"div\",null,{\"style\":{\"display\":\"inline-block\"},\"children\":[\"$\",\"h2\",null,{\"style\":{\"fontSize\":14,\"fontWeight\":400,\"lineHeight\":\"49px\",\"margin\":0},\"children\":\"This page could not be found.\"}]}]]}]}]],[]],\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}],[\"$\",\"footer\",null,{\"children\":[\"$\",\"div\",null,{\"className\":\"container\",\"children\":[[\"$\",\"div\",null,{\"className\":\"footer-content\",\"children\":[[\"$\",\"div\",null,{\"className\":\"footer-section\",\"children\":[[\"$\",\"h4\",null,{\"children\":\"Zen LM\"}],[\"$\",\"p\",null,{\"children\":\"Open foundation models for agentic AI. 30+ models from 0.6B to 1T parameters.\"}]]}],[\"$\",\"div\",null,{\"className\":\"footer-section\",\"children\":[[\"$\",\"h4\",null,{\"children\":\"Zen Coder\"}],[\"$\",\"ul\",null,{\"children\":[[\"$\",\"li\",null,{\"children\":[\"$\",\"$L5\",null,{\"href\":\"/models#zen-coder\",\"children\":\"Zen Coder 4B\"}]}],[\"$\",\"li\",null,{\"children\":[\"$\",\"$L5\",null,{\"href\":\"/models#zen-coder\",\"children\":\"Zen Coder 24B\"}]}],[\"$\",\"li\",null,{\"children\":[\"$\",\"$L5\",null,{\"href\":\"/models#zen-coder\",\"children\":\"Zen Coder 123B\"}]}],[\"$\",\"li\",null,{\"children\":[\"$\",\"$L5\",null,{\"href\":\"/models#zen-coder\",\"children\":\"Zen Coder Max (358B)\"}]}],[\"$\",\"li\",null,{\"children\":[\"$\",\"$L5\",null,{\"href\":\"/models#zen-coder\",\"children\":\"Zen Coder Ultra (1T)\"}]}]]}]]}],[\"$\",\"div\",null,{\"className\":\"footer-section\",\"children\":[[\"$\",\"h4\",null,{\"children\":\"Model Family\"}],[\"$\",\"ul\",null,{\"children\":[[\"$\",\"li\",null,{\"children\":[\"$\",\"$L5\",null,{\"href\":\"/models#core-models\",\"children\":\"zen-nano (0.6B)\"}]}],[\"$\",\"li\",null,{\"children\":[\"$\",\"$L5\",null,{\"href\":\"/models#core-models\",\"children\":\"zen-eco (4B)\"}]}],[\"$\",\"li\",null,{\"children\":[\"$\",\"$L5\",null,{\"href\":\"/models#core-models\",\"children\":\"zen-omni (7B)\"}]}],[\"$\",\"li\",null,{\"children\":[\"$\",\"$L5\",null,{\"href\":\"/models#multimodal\",\"children\":\"zen-vl (Vision)\"}]}],[\"$\",\"li\",null,{\"children\":[\"$\",\"$L5\",null,{\"href\":\"/models#multimodal\",\"children\":\"zen-3d (3D Gen)\"}]}]]}]]}],[\"$\",\"div\",null,{\"className\":\"footer-section\",\"children\":[[\"$\",\"h4\",null,{\"children\":\"Resources\"}],[\"$\",\"ul\",null,{\"children\":[[\"$\",\"li\",null,{\"children\":[\"$\",\"$L5\",null,{\"href\":\"/datasets\",\"children\":\"Training Data\"}]}],[\"$\",\"li\",null,{\"children\":[\"$\",\"a\",null,{\"href\":\"https://huggingface.co/zenlm\",\"target\":\"_blank\",\"rel\":\"noopener noreferrer\",\"children\":\"HuggingFace\"}]}],[\"$\",\"li\",null,{\"children\":[\"$\",\"a\",null,{\"href\":\"https://github.com/zenlm\",\"target\":\"_blank\",\"rel\":\"noopener noreferrer\",\"children\":\"GitHub\"}]}],[\"$\",\"li\",null,{\"children\":[\"$\",\"$L5\",null,{\"href\":\"/research\",\"children\":\"Research Papers\"}]}],[\"$\",\"li\",null,{\"children\":[\"$\",\"a\",null,{\"href\":\"https://github.com/zenlm/zen-trainer\",\"target\":\"_blank\",\"rel\":\"noopener noreferrer\",\"children\":\"zen-trainer\"}]}]]}]]}]]}],[\"$\",\"div\",null,{\"className\":\"footer-bottom\",\"children\":[\"$\",\"p\",null,{\"children\":\"¬© 2025 Zen Authors. All rights reserved. Built with clarity and purpose.\"}]}]]}]}],[\"$\",\"script\",null,{\"src\":\"/assets/js/main.js\",\"async\":true}]]}]]}]]}],{\"children\":[\"__PAGE__\",[\"$\",\"$1\",\"c\",{\"children\":[[\"$\",\"main\",null,{\"children\":[[\"$\",\"section\",null,{\"className\":\"hero\",\"children\":[\"$\",\"div\",null,{\"className\":\"container\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"hero-title\",\"children\":\"Open Foundation Models for Agentic AI\"}],[\"$\",\"p\",null,{\"className\":\"hero-subtitle\",\"children\":\"30+ models from 0.6B to 1T parameters across language, vision, audio, video, and 3D\"}],\"$L6\",\"$L7\"]}]}],\"$L8\",\"$L9\",\"$La\",\"$Lb\"]}],null,\"$Lc\"]}],{},null,false]},null,false],\"$Ld\",false]],\"m\":\"$undefined\",\"G\":[\"$e\",[]],\"s\":false,\"S\":true}\n"])</script><script>self.__next_f.push([1,"f:I[4431,[],\"OutletBoundary\"]\n11:I[5278,[],\"AsyncMetadataOutlet\"]\n13:I[4431,[],\"ViewportBoundary\"]\n15:I[4431,[],\"MetadataBoundary\"]\n16:\"$Sreact.suspense\"\n6:[\"$\",\"p\",null,{\"className\":\"hero-description\",\"children\":\"Zen LM provides production-ready AI models for agentic coding, multimodal understanding, and creative generation. Our flagship Zen Coder models are trained on 8.47 billion tokens of real-world programming sessions, delivering state-of-the-art performance on agentic programming tasks.\"}]\n7:[\"$\",\"div\",null,{\"className\":\"hero-cta\",\"children\":[[\"$\",\"$L5\",null,{\"href\":\"/models\",\"className\":\"btn btn-primary\",\"children\":\"Explore Models\"}],[\"$\",\"$L5\",null,{\"href\":\"/datasets\",\"className\":\"btn btn-secondary\",\"children\":\"Training Data\"}],[\"$\",\"$L5\",null,{\"href\":\"/research\",\"className\":\"btn btn-outline\",\"children\":\"Research Papers\"}]]}]\n"])</script><script>self.__next_f.push([1,"8:[\"$\",\"section\",null,{\"id\":\"zen-coder\",\"className\":\"featured-section\",\"children\":[\"$\",\"div\",null,{\"className\":\"container\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"section-title\",\"children\":\"Zen Coder - Agentic Coding Models\"}],[\"$\",\"p\",null,{\"className\":\"section-subtitle\",\"children\":\"Fine-tuned on 8.47B tokens of real programming sessions\"}],[\"$\",\"div\",null,{\"className\":\"model-lineup\",\"children\":[\"$\",\"table\",null,{\"className\":\"models-table\",\"children\":[[\"$\",\"thead\",null,{\"children\":[\"$\",\"tr\",null,{\"children\":[[\"$\",\"th\",null,{\"children\":\"Model\"}],[\"$\",\"th\",null,{\"children\":\"Size\"}],[\"$\",\"th\",null,{\"children\":\"Base\"}],[\"$\",\"th\",null,{\"children\":\"VRAM\"}],[\"$\",\"th\",null,{\"children\":\"Context\"}],[\"$\",\"th\",null,{\"children\":\"Status\"}]]}]}],[\"$\",\"tbody\",null,{\"children\":[[\"$\",\"tr\",null,{\"children\":[[\"$\",\"td\",null,{\"children\":[\"$\",\"strong\",null,{\"children\":\"Zen Coder 4B\"}]}],[\"$\",\"td\",null,{\"children\":\"4B\"}],[\"$\",\"td\",null,{\"children\":\"Qwen3-4B-Instruct\"}],[\"$\",\"td\",null,{\"children\":\"8 GB\"}],[\"$\",\"td\",null,{\"children\":\"32K\"}],[\"$\",\"td\",null,{\"children\":[\"$\",\"span\",null,{\"className\":\"status-trained\",\"children\":\"Trained\"}]}]]}],[\"$\",\"tr\",null,{\"children\":[[\"$\",\"td\",null,{\"children\":[\"$\",\"strong\",null,{\"children\":\"Zen Coder 24B\"}]}],[\"$\",\"td\",null,{\"children\":\"24B\"}],[\"$\",\"td\",null,{\"children\":\"Devstral Small 2\"}],[\"$\",\"td\",null,{\"children\":\"24 GB\"}],[\"$\",\"td\",null,{\"children\":\"256K\"}],[\"$\",\"td\",null,{\"children\":[\"$\",\"span\",null,{\"className\":\"status-trained\",\"children\":\"Trained\"}]}]]}],[\"$\",\"tr\",null,{\"children\":[[\"$\",\"td\",null,{\"children\":[\"$\",\"strong\",null,{\"children\":\"Zen Coder 123B\"}]}],[\"$\",\"td\",null,{\"children\":\"123B\"}],[\"$\",\"td\",null,{\"children\":\"Devstral 2\"}],[\"$\",\"td\",null,{\"children\":\"128 GB\"}],[\"$\",\"td\",null,{\"children\":\"256K\"}],[\"$\",\"td\",null,{\"children\":[\"$\",\"span\",null,{\"className\":\"status-training\",\"children\":\"Training\"}]}]]}],[\"$\",\"tr\",null,{\"children\":[[\"$\",\"td\",null,{\"children\":[\"$\",\"strong\",null,{\"children\":\"Zen Coder Max\"}]}],[\"$\",\"td\",null,{\"children\":\"358B\"}],[\"$\",\"td\",null,{\"children\":\"GLM-4.7 (MoE)\"}],[\"$\",\"td\",null,{\"children\":\"180 GB\"}],[\"$\",\"td\",null,{\"children\":\"200K\"}],[\"$\",\"td\",null,{\"children\":[\"$\",\"span\",null,{\"className\":\"status-planned\",\"children\":\"Planned\"}]}]]}],[\"$\",\"tr\",null,{\"children\":[[\"$\",\"td\",null,{\"children\":[\"$\",\"strong\",null,{\"children\":\"Zen Coder Ultra\"}]}],[\"$\",\"td\",null,{\"children\":\"1T\"}],[\"$\",\"td\",null,{\"children\":\"Kimi K2 (MoE)\"}],[\"$\",\"td\",null,{\"children\":\"256 GB\"}],[\"$\",\"td\",null,{\"children\":\"128K\"}],[\"$\",\"td\",null,{\"children\":[\"$\",\"span\",null,{\"className\":\"status-planned\",\"children\":\"Planned\"}]}]]}]]}]]}]}],[\"$\",\"div\",null,{\"className\":\"coder-features arch-grid\",\"children\":[[\"$\",\"div\",null,{\"className\":\"arch-card\",\"children\":[[\"$\",\"h3\",null,{\"children\":\"Real Agentic Data\"}],[\"$\",\"p\",null,{\"children\":\"Trained on actual agentic debug sessions - not synthetic data. Real debugging workflows, multi-file refactoring, and tool use patterns.\"}]]}],[\"$\",\"div\",null,{\"className\":\"arch-card\",\"children\":[[\"$\",\"h3\",null,{\"children\":\"Production Code\"}],[\"$\",\"p\",null,{\"children\":\"15 years of professional development across AI, Web3, cryptography, and modern software engineering from 1,452 repositories.\"}]]}],[\"$\",\"div\",null,{\"className\":\"arch-card\",\"children\":[[\"$\",\"h3\",null,{\"children\":\"Open Training\"}],[\"$\",\"p\",null,{\"children\":[\"Use \",[\"$\",\"a\",null,{\"href\":\"https://github.com/zenlm/zen-trainer\",\"children\":\"zen-trainer\"}],\" to fine-tune on your own data. Supports MLX (Apple Silicon), Unsloth, and DeepSpeed.\"]}]]}]]}]]}]}]\n"])</script><script>self.__next_f.push([1,"9:[\"$\",\"section\",null,{\"id\":\"overview\",\"className\":\"architecture-section\",\"children\":[\"$\",\"div\",null,{\"className\":\"container\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"section-title\",\"children\":\"Complete AI Model Ecosystem\"}],[\"$\",\"div\",null,{\"className\":\"arch-grid\",\"children\":[[\"$\",\"div\",null,{\"className\":\"arch-card\",\"children\":[[\"$\",\"div\",null,{\"className\":\"arch-icon\",\"children\":\"üß†\"}],[\"$\",\"h3\",null,{\"children\":\"Language Models\"}],[\"$\",\"p\",null,{\"children\":\"6 core models from 0.6B to 32B. zen-nano for edge, zen-eco for efficiency, zen-omni for multimodal, zen-next for frontier reasoning.\"}]]}],[\"$\",\"div\",null,{\"className\":\"arch-card\",\"children\":[[\"$\",\"div\",null,{\"className\":\"arch-icon\",\"children\":\"üíª\"}],[\"$\",\"h3\",null,{\"children\":\"Zen Coder\"}],[\"$\",\"p\",null,{\"children\":\"5 coding models from 4B to 1T trained on 8.47B tokens of agentic programming data. State-of-the-art on tool use and multi-step coding.\"}]]}],[\"$\",\"div\",null,{\"className\":\"arch-card\",\"children\":[[\"$\",\"div\",null,{\"className\":\"arch-icon\",\"children\":\"üëÅÔ∏è\"}],[\"$\",\"h3\",null,{\"children\":\"Vision \u0026 Multimodal\"}],[\"$\",\"p\",null,{\"children\":\"zen-vl for vision-language, zen-designer for visual understanding, zen-artist for image generation, zen-omni for unified multimodal.\"}]]}],[\"$\",\"div\",null,{\"className\":\"arch-card\",\"children\":[[\"$\",\"div\",null,{\"className\":\"arch-icon\",\"children\":\"üé¨\"}],[\"$\",\"h3\",null,{\"children\":\"Video \u0026 3D\"}],[\"$\",\"p\",null,{\"children\":\"zen-director for video generation, zen-video for high-quality synthesis, zen-3d for 3D assets, zen-world for world simulation.\"}]]}],[\"$\",\"div\",null,{\"className\":\"arch-card\",\"children\":[[\"$\",\"div\",null,{\"className\":\"arch-icon\",\"children\":\"üéµ\"}],[\"$\",\"h3\",null,{\"children\":\"Audio\"}],[\"$\",\"p\",null,{\"children\":\"zen-musician for music generation, zen-foley for sound effects, zen-scribe for transcription, zen-dub for voice dubbing.\"}]]}],[\"$\",\"div\",null,{\"className\":\"arch-card\",\"children\":[[\"$\",\"div\",null,{\"className\":\"arch-icon\",\"children\":\"üõ°Ô∏è\"}],[\"$\",\"h3\",null,{\"children\":\"Specialized\"}],[\"$\",\"p\",null,{\"children\":\"zen-guard for safety, zen-embedding for vectors, zen-reranker for search, zen-translator for translation, zen-agent for tool use.\"}]]}]]}]]}]}]\n"])</script><script>self.__next_f.push([1,"a:[\"$\",\"section\",null,{\"id\":\"dataset\",\"className\":\"dataset-section\",\"children\":[\"$\",\"div\",null,{\"className\":\"container\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"section-title\",\"children\":\"Zen Agentic Dataset\"}],[\"$\",\"p\",null,{\"className\":\"section-subtitle\",\"children\":\"8.47 Billion Tokens of Real-World Agentic Programming\"}],[\"$\",\"div\",null,{\"className\":\"arch-grid\",\"children\":[[\"$\",\"div\",null,{\"className\":\"arch-card\",\"children\":[[\"$\",\"div\",null,{\"className\":\"arch-icon\",\"children\":\"8.47B\"}],[\"$\",\"h3\",null,{\"children\":\"Tokens\"}],[\"$\",\"p\",null,{\"children\":\"Total training tokens across all data sources\"}]]}],[\"$\",\"div\",null,{\"className\":\"arch-card\",\"children\":[[\"$\",\"div\",null,{\"className\":\"arch-icon\",\"children\":\"3.35M\"}],[\"$\",\"h3\",null,{\"children\":\"Samples\"}],[\"$\",\"p\",null,{\"children\":\"Training samples with conversation context\"}]]}],[\"$\",\"div\",null,{\"className\":\"arch-card\",\"children\":[[\"$\",\"div\",null,{\"className\":\"arch-icon\",\"children\":\"1,452\"}],[\"$\",\"h3\",null,{\"children\":\"Repositories\"}],[\"$\",\"p\",null,{\"children\":\"Open source and private codebases\"}]]}],[\"$\",\"div\",null,{\"className\":\"arch-card\",\"children\":[[\"$\",\"div\",null,{\"className\":\"arch-icon\",\"children\":\"15yr\"}],[\"$\",\"h3\",null,{\"children\":\"History\"}],[\"$\",\"p\",null,{\"children\":\"Years of development history (2010-2025)\"}]]}]]}],[\"$\",\"div\",null,{\"className\":\"dataset-cta\",\"style\":{\"textAlign\":\"center\",\"marginTop\":\"2rem\"},\"children\":[[\"$\",\"p\",null,{\"children\":\"Available for research and commercial licensing.\"}],[\"$\",\"a\",null,{\"href\":\"mailto:z@hanzo.ai\",\"className\":\"btn btn-primary\",\"children\":\"Request Access\"}],[\"$\",\"a\",null,{\"href\":\"https://huggingface.co/datasets/hanzoai/zen-agentic-dataset\",\"className\":\"btn btn-secondary\",\"target\":\"_blank\",\"rel\":\"noopener noreferrer\",\"children\":\"View on HuggingFace\"}]]}]]}]}]\n"])</script><script>self.__next_f.push([1,"b:[\"$\",\"section\",null,{\"id\":\"downloads\",\"className\":\"downloads-section\",\"children\":[\"$\",\"div\",null,{\"className\":\"container\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"section-title\",\"children\":\"Get Started\"}],[\"$\",\"div\",null,{\"className\":\"download-grid\",\"children\":[[\"$\",\"div\",null,{\"className\":\"download-card\",\"children\":[[\"$\",\"h3\",null,{\"children\":\"HuggingFace\"}],[\"$\",\"p\",null,{\"children\":\"Access all 30+ models via HuggingFace Hub\"}],[\"$\",\"a\",null,{\"href\":\"https://huggingface.co/zenlm\",\"className\":\"btn btn-primary\",\"target\":\"_blank\",\"rel\":\"noopener noreferrer\",\"children\":\"Visit HuggingFace\"}]]}],[\"$\",\"div\",null,{\"className\":\"download-card\",\"children\":[[\"$\",\"h3\",null,{\"children\":\"GitHub\"}],[\"$\",\"p\",null,{\"children\":\"Training code, documentation, and source\"}],[\"$\",\"a\",null,{\"href\":\"https://github.com/zenlm\",\"className\":\"btn btn-primary\",\"target\":\"_blank\",\"rel\":\"noopener noreferrer\",\"children\":\"View on GitHub\"}]]}],[\"$\",\"div\",null,{\"className\":\"download-card\",\"children\":[[\"$\",\"h3\",null,{\"children\":\"zen-trainer\"}],[\"$\",\"p\",null,{\"children\":\"Fine-tune models on your own data\"}],[\"$\",\"pre\",null,{\"children\":[\"$\",\"code\",null,{\"children\":\"pip install zen-trainer\"}]}]]}],[\"$\",\"div\",null,{\"className\":\"download-card\",\"children\":[[\"$\",\"h3\",null,{\"children\":\"Research\"}],[\"$\",\"p\",null,{\"children\":\"Technical papers and whitepapers\"}],[\"$\",\"$L5\",null,{\"href\":\"/research\",\"className\":\"btn btn-primary\",\"children\":\"Read Papers\"}]]}]]}]]}]}]\n"])</script><script>self.__next_f.push([1,"c:[\"$\",\"$Lf\",null,{\"children\":[\"$L10\",[\"$\",\"$L11\",null,{\"promise\":\"$@12\"}]]}]\nd:[\"$\",\"$1\",\"h\",{\"children\":[null,[[\"$\",\"$L13\",null,{\"children\":\"$L14\"}],null],[\"$\",\"$L15\",null,{\"children\":[\"$\",\"div\",null,{\"hidden\":true,\"children\":[\"$\",\"$16\",null,{\"fallback\":null,\"children\":\"$L17\"}]}]}]]}]\n"])</script><script>self.__next_f.push([1,"14:[[\"$\",\"meta\",\"0\",{\"charSet\":\"utf-8\"}],[\"$\",\"meta\",\"1\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}]]\n10:null\n"])</script><script>self.__next_f.push([1,"12:{\"metadata\":[[\"$\",\"title\",\"0\",{\"children\":\"Zen LM - Open Foundation Models for Agentic AI\"}],[\"$\",\"meta\",\"1\",{\"name\":\"description\",\"content\":\"30+ open models from 0.6B to 1T parameters. Flagship Zen Coder trained on 8.47B tokens of real programming sessions.\"}],[\"$\",\"meta\",\"2\",{\"name\":\"keywords\",\"content\":\"AI, LLM, Agentic AI, Code Generation, Zen Coder, Multimodal, Open Source, Machine Learning\"}]],\"error\":null,\"digest\":\"$undefined\"}\n"])</script><script>self.__next_f.push([1,"17:\"$12:metadata\"\n"])</script></body></html>