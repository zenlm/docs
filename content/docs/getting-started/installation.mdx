---
title: Installation
description: Install dependencies for using Zen models
---

# Installation

## Requirements

- Python 3.10+
- PyTorch 2.2+
- CUDA 12.1+ (for GPU inference)

## Install Transformers

```bash
pip install torch transformers accelerate
```

## Install vLLM (Production)

```bash
pip install vllm
```

## Install MLX (Apple Silicon)

```bash
pip install mlx mlx-lm
```

## Install SGLang

```bash
pip install sglang[all]
```

## GPU Memory Requirements

| Model | Minimum VRAM | Recommended |
|-------|--------------|-------------|
| zen-nano | 2GB | 4GB |
| zen-coder-4b | 8GB | 16GB |
| zen-coder-flash | 24GB | 48GB |
| zen-max | 160GB | 320GB |

<Callout type="info">
  zen-coder-flash uses MoE architecture with 31B total params but only 3B active, making it efficient for its capability level.
</Callout>
