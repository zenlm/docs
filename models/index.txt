1:"$Sreact.fragment"
2:I[1398,["619","static/chunks/619-ba102abea3e3d0e4.js","394","static/chunks/394-7ae625d7fca91f5c.js","177","static/chunks/app/layout-69b551721b5ae1f6.js"],"default"]
3:I[9766,[],""]
4:I[8924,[],""]
5:I[2619,["619","static/chunks/619-ba102abea3e3d0e4.js","974","static/chunks/app/page-6f8a3b3ea33cc66d.js"],""]
d:I[7150,[],""]
:HL["/_next/static/css/1d1f6bc532e5f43f.css","style"]
0:{"P":null,"b":"2ezz-PBbsRcymwbmfjjIq","p":"","c":["","models",""],"i":false,"f":[[["",{"children":["models",{"children":["__PAGE__",{}]}]},"$undefined","$undefined",true],["",["$","$1","c",{"children":[[["$","link","0",{"rel":"stylesheet","href":"/_next/static/css/1d1f6bc532e5f43f.css","precedence":"next","crossOrigin":"$undefined","nonce":"$undefined"}]],["$","html",null,{"lang":"en","children":[["$","head",null,{"children":["$","link",null,{"rel":"icon","type":"image/png","href":"/favicon.png"}]}],["$","body",null,{"children":[["$","$L2",null,{}],["$","$L3",null,{"parallelRouterKey":"children","error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L4",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":[[["$","title",null,{"children":"404: This page could not be found."}],["$","div",null,{"style":{"fontFamily":"system-ui,\"Segoe UI\",Roboto,Helvetica,Arial,sans-serif,\"Apple Color Emoji\",\"Segoe UI Emoji\"","height":"100vh","textAlign":"center","display":"flex","flexDirection":"column","alignItems":"center","justifyContent":"center"},"children":["$","div",null,{"children":[["$","style",null,{"dangerouslySetInnerHTML":{"__html":"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}"}}],["$","h1",null,{"className":"next-error-h1","style":{"display":"inline-block","margin":"0 20px 0 0","padding":"0 23px 0 0","fontSize":24,"fontWeight":500,"verticalAlign":"top","lineHeight":"49px"},"children":404}],["$","div",null,{"style":{"display":"inline-block"},"children":["$","h2",null,{"style":{"fontSize":14,"fontWeight":400,"lineHeight":"49px","margin":0},"children":"This page could not be found."}]}]]}]}]],[]],"forbidden":"$undefined","unauthorized":"$undefined"}],["$","footer",null,{"children":["$","div",null,{"className":"container","children":[["$","div",null,{"className":"footer-content","children":[["$","div",null,{"className":"footer-section","children":[["$","h4",null,{"children":"Zen LM"}],["$","p",null,{"children":"Open foundation models for agentic AI. 30+ models from 0.6B to 1T parameters."}]]}],["$","div",null,{"className":"footer-section","children":[["$","h4",null,{"children":"Zen Coder"}],["$","ul",null,{"children":[["$","li",null,{"children":["$","$L5",null,{"href":"/models#zen-coder","children":"Zen Coder 4B"}]}],["$","li",null,{"children":["$","$L5",null,{"href":"/models#zen-coder","children":"Zen Coder 24B"}]}],["$","li",null,{"children":["$","$L5",null,{"href":"/models#zen-coder","children":"Zen Coder 123B"}]}],["$","li",null,{"children":["$","$L5",null,{"href":"/models#zen-coder","children":"Zen Coder Max (358B)"}]}],["$","li",null,{"children":["$","$L5",null,{"href":"/models#zen-coder","children":"Zen Coder Ultra (1T)"}]}]]}]]}],["$","div",null,{"className":"footer-section","children":[["$","h4",null,{"children":"Model Family"}],["$","ul",null,{"children":[["$","li",null,{"children":["$","$L5",null,{"href":"/models#core-models","children":"zen-nano (0.6B)"}]}],["$","li",null,{"children":["$","$L5",null,{"href":"/models#core-models","children":"zen-eco (4B)"}]}],["$","li",null,{"children":["$","$L5",null,{"href":"/models#core-models","children":"zen-omni (7B)"}]}],["$","li",null,{"children":["$","$L5",null,{"href":"/models#multimodal","children":"zen-vl (Vision)"}]}],["$","li",null,{"children":["$","$L5",null,{"href":"/models#multimodal","children":"zen-3d (3D Gen)"}]}]]}]]}],["$","div",null,{"className":"footer-section","children":[["$","h4",null,{"children":"Resources"}],["$","ul",null,{"children":[["$","li",null,{"children":["$","$L5",null,{"href":"/datasets","children":"Training Data"}]}],["$","li",null,{"children":["$","a",null,{"href":"https://huggingface.co/zenlm","target":"_blank","rel":"noopener noreferrer","children":"HuggingFace"}]}],["$","li",null,{"children":["$","a",null,{"href":"https://github.com/zenlm","target":"_blank","rel":"noopener noreferrer","children":"GitHub"}]}],["$","li",null,{"children":["$","$L5",null,{"href":"/research","children":"Research Papers"}]}],["$","li",null,{"children":["$","a",null,{"href":"https://github.com/zenlm/zen-trainer","target":"_blank","rel":"noopener noreferrer","children":"zen-trainer"}]}]]}]]}]]}],["$","div",null,{"className":"footer-bottom","children":["$","p",null,{"children":"Â© 2025 Zen Authors. All rights reserved. Built with clarity and purpose."}]}]]}]}],["$","script",null,{"src":"/assets/js/main.js","async":true}]]}]]}]]}],{"children":["models",["$","$1","c",{"children":[null,["$","$L3",null,{"parallelRouterKey":"children","error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L4",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","forbidden":"$undefined","unauthorized":"$undefined"}]]}],{"children":["__PAGE__",["$","$1","c",{"children":[["$","main",null,{"children":[["$","section",null,{"className":"hero","children":["$","div",null,{"className":"container","children":["$L6","$L7","$L8"]}]}],"$L9","$La"]}],null,"$Lb"]}],{},null,false]},null,false]},null,false],"$Lc",false]],"m":"$undefined","G":["$d",[]],"s":false,"S":true}
1f:I[4431,[],"OutletBoundary"]
21:I[5278,[],"AsyncMetadataOutlet"]
23:I[4431,[],"ViewportBoundary"]
25:I[4431,[],"MetadataBoundary"]
26:"$Sreact.suspense"
6:["$","h2",null,{"className":"hero-title","children":"Zen Model Family"}]
7:["$","p",null,{"className":"hero-subtitle","children":"24+ models spanning language, vision, audio, video, 3D, and specialized tasks"}]
8:["$","p",null,{"className":"hero-description","children":"Complete model collection from 0.6B to 1T+ parameters. From efficient edge deployment to powerful cloud inference, each model is optimized for specific use cases while maintaining the same high standards of performance, transparency, and open-source accessibility."}]
9:["$","section",null,{"id":"core-models","className":"models-section","children":["$","div",null,{"className":"container","children":[["$","h2",null,{"className":"section-title","children":"Core Language Models"}],["$","p",null,{"className":"section-subtitle","children":"Foundational models from nano to next-gen"}],["$","div",null,{"className":"models-grid","children":[["$","div",null,{"className":"model-card complete","children":[["$","div",null,{"className":"model-header","children":[["$","h3",null,{"children":"zen-nano"}],["$","span",null,{"className":"badge badge-complete","children":"Available"}]]}],["$","div",null,{"className":"model-specs","children":[["$","div","0",{"className":"spec","children":[["$","span",null,{"className":"spec-label","children":"Parameters"}],["$","span",null,{"className":"spec-value","children":"0.6B"}]]}],["$","div","1",{"className":"spec","children":[["$","span",null,{"className":"spec-label","children":"Base"}],["$","span",null,{"className":"spec-value","children":"Qwen3-0.6B"}]]}],["$","div","2",{"className":"spec","children":[["$","span",null,{"className":"spec-label","children":"Context"}],["$","span",null,{"className":"spec-value","children":"32K tokens"}]]}],["$","div","3",{"className":"spec","children":[["$","span",null,{"className":"spec-label","children":"Architecture"}],["$","span",null,{"className":"spec-value","children":"28 layers, GQA"}]]}]]}],["$","p",null,{"className":"model-description","children":"Ultra-efficient model for edge deployment and embedded systems. Perfect for on-device AI applications with minimal resource requirements."}],["$","div",null,{"className":"model-formats","children":[["$","span","0",{"className":"format-tag","children":"SafeTensors"}],["$","span","1",{"className":"format-tag","children":"GGUF"}],["$","span","2",{"className":"format-tag","children":"MLX"}]]}],["$","div",null,{"className":"model-actions","children":[["$","a",null,{"href":"https://huggingface.co/zenlm/zen-nano","className":"btn btn-sm btn-primary","target":"_blank","rel":"noopener noreferrer","children":"ðŸ¤— HF"}],["$","a",null,{"href":"https://github.com/zenlm/zen-nano","className":"btn btn-sm btn-secondary","target":"_blank","rel":"noopener noreferrer","children":"ðŸ“¦ GitHub"}],["$","a",null,{"href":"https://github.com/zenlm/zen-nano/tree/main/docs","className":"btn btn-sm btn-secondary","target":"_blank","rel":"noopener noreferrer","children":"ðŸ“– Docs"}],["$","a",null,{"href":"/papers/zen-nano_whitepaper.pdf","className":"btn btn-sm btn-secondary","target":"_blank","rel":"noopener noreferrer","children":"ðŸ“„ Paper"}]]}]]}],["$","div",null,{"className":"model-card complete","children":[["$","div",null,{"className":"model-header","children":[["$","h3",null,{"children":"zen-eco"}],["$","span",null,{"className":"badge badge-complete","children":"Available"}]]}],["$","div",null,{"className":"model-specs","children":[["$","div","0",{"className":"spec","children":[["$","span",null,{"className":"spec-label","children":"Parameters"}],["$","span",null,{"className":"spec-value","children":"4B"}]]}],["$","div","1",{"className":"spec","children":[["$","span",null,{"className":"spec-label","children":"Base"}],["$","span",null,{"className":"spec-value","children":"Qwen3-3B"}]]}],["$","div","2",{"className":"spec","children":[["$","span",null,{"className":"spec-label","children":"Context"}],["$","span",null,{"className":"spec-value","children":"32K tokens"}]]}],["$","div","3",{"className":"spec","children":[["$","span",null,{"className":"spec-label","children":"Variants"}],["$","span",null,{"className":"spec-value","children":"Instruct, Agent, Coder, Thinking"}]]}]]}],["$","p",null,{"className":"model-description","children":"Balanced performance and efficiency for general-purpose applications. Multiple specialized variants for different use cases."}],["$","div",null,{"className":"model-formats","children":[["$","span","0",{"className":"format-tag","children":"SafeTensors"}],["$","span","1",{"className":"format-tag","children":"GGUF"}],["$","span","2",{"className":"format-tag","children":"MLX"}]]}],["$","div",null,{"className":"model-actions","children":[["$","a",null,{"href":"https://huggingface.co/zenlm/zen-eco","className":"btn btn-sm btn-primary","target":"_blank","rel":"noopener noreferrer","children":"ðŸ¤— HF"}],["$","a",null,{"href":"https://github.com/zenlm/zen-eco","className":"btn btn-sm btn-secondary","target":"_blank","rel":"noopener noreferrer","children":"ðŸ“¦ GitHub"}],"$undefined","$undefined"]}]]}],["$","div",null,{"className":"model-card complete","children":[["$","div",null,{"className":"model-header","children":["$Le","$Lf"]}],"$L10","$L11","$L12","$L13"]}],"$L14","$L15"]}]]}]}]
a:["$","section",null,{"id":"multimodal","className":"models-section","children":["$","div",null,{"className":"container","children":[["$","h2",null,{"className":"section-title","children":"Multimodal Models"}],["$","p",null,{"className":"section-subtitle","children":"Vision, Audio, Video, and 3D Generation"}],["$","div",null,{"className":"models-grid","children":[["$","div",null,{"className":"model-card complete","children":[["$","div",null,{"className":"model-header","children":[["$","h3",null,{"children":"zen-vl"}],["$","span",null,{"className":"badge badge-complete","children":"Available"}]]}],["$","div",null,{"className":"model-specs","children":[["$","div","0",{"className":"spec","children":[["$","span",null,{"className":"spec-label","children":"Type"}],["$","span",null,{"className":"spec-value","children":"Vision-Language"}]]}],["$","div","1",{"className":"spec","children":[["$","span",null,{"className":"spec-label","children":"Base"}],["$","span",null,{"className":"spec-value","children":"Qwen3-VL"}]]}],["$","div","2",{"className":"spec","children":[["$","span",null,{"className":"spec-label","children":"Sizes"}],["$","span",null,{"className":"spec-value","children":"4B, 8B, 30B"}]]}],["$","div","3",{"className":"spec","children":[["$","span",null,{"className":"spec-label","children":"Variants"}],["$","span",null,{"className":"spec-value","children":"Instruct, Agent"}]]}],["$","div","4",{"className":"spec","children":[["$","span",null,{"className":"spec-label","children":"Focus"}],["$","span",null,{"className":"spec-value","children":"Function Calling"}]]}]]}],["$","p",null,{"className":"model-description","children":"Next-generation vision-language model with advanced function calling capabilities. Trained on Agent Data Protocol (ADP) and xLAM datasets for superior agent performance and tool use."}],["$","div",null,{"className":"model-formats","children":[["$","span","0",{"className":"format-tag","children":"SafeTensors"}],["$","span","1",{"className":"format-tag","children":"GGUF"}]]}],["$","div",null,{"className":"model-actions","children":[["$","a",null,{"href":"https://huggingface.co/zenlm/zen-vl-4b-instruct","className":"btn btn-sm btn-primary","target":"_blank","rel":"noopener noreferrer","children":"ðŸ¤— HF"}],["$","a",null,{"href":"https://github.com/zenlm/zen-vl","className":"btn btn-sm btn-secondary","target":"_blank","rel":"noopener noreferrer","children":"ðŸ“¦ GitHub"}],"$undefined","$undefined"]}]]}],["$","div",null,{"className":"model-card complete","children":[["$","div",null,{"className":"model-header","children":[["$","h3",null,{"children":"zen-designer"}],["$","span",null,{"className":"badge badge-complete","children":"Available"}]]}],["$","div",null,{"className":"model-specs","children":[["$","div","0",{"className":"spec","children":[["$","span",null,{"className":"spec-label","children":"Type"}],["$","span",null,{"className":"spec-value","children":"Vision-Language"}]]}],["$","div","1",{"className":"spec","children":[["$","span",null,{"className":"spec-label","children":"Base"}],["$","span",null,{"className":"spec-value","children":"Qwen-VL"}]]}],["$","div","2",{"className":"spec","children":[["$","span",null,{"className":"spec-label","children":"Variants"}],["$","span",null,{"className":"spec-value","children":"Instruct, Thinking"}]]}],["$","div","3",{"className":"spec","children":[["$","span",null,{"className":"spec-label","children":"Focus"}],["$","span",null,{"className":"spec-value","children":"Visual Understanding"}]]}]]}],["$","p",null,{"className":"model-description","children":"Advanced vision-language model for image understanding, analysis, and reasoning. Supports visual question answering, OCR, and detailed scene description."}],["$","div",null,{"className":"model-formats","children":[["$","span","0",{"className":"format-tag","children":"SafeTensors"}]]}],["$","div",null,{"className":"model-actions","children":["$undefined",["$","a",null,{"href":"https://github.com/zenlm/zen-designer","className":"btn btn-sm btn-secondary","target":"_blank","rel":"noopener noreferrer","children":"ðŸ“¦ GitHub"}],"$undefined","$undefined"]}]]}],["$","div",null,{"className":"model-card complete","children":[["$","div",null,{"className":"model-header","children":[["$","h3",null,{"children":"zen-artist"}],["$","span",null,{"className":"badge badge-complete","children":"Available"}]]}],["$","div",null,{"className":"model-specs","children":[["$","div","0",{"className":"spec","children":[["$","span",null,{"className":"spec-label","children":"Type"}],["$","span",null,{"className":"spec-value","children":"Text-to-Image"}]]}],["$","div","1",{"className":"spec","children":[["$","span",null,{"className":"spec-label","children":"Base"}],"$L16"]}],"$L17","$L18"]}],"$L19","$L1a","$L1b"]}],"$L1c","$L1d","$L1e"]}]]}]}]
b:["$","$L1f",null,{"children":["$L20",["$","$L21",null,{"promise":"$@22"}]]}]
c:["$","$1","h",{"children":[null,[["$","$L23",null,{"children":"$L24"}],null],["$","$L25",null,{"children":["$","div",null,{"hidden":true,"children":["$","$26",null,{"fallback":null,"children":"$L27"}]}]}]]}]
e:["$","h3",null,{"children":"zen-omni"}]
f:["$","span",null,{"className":"badge badge-complete","children":"Available"}]
10:["$","div",null,{"className":"model-specs","children":[["$","div","0",{"className":"spec","children":[["$","span",null,{"className":"spec-label","children":"Parameters"}],["$","span",null,{"className":"spec-value","children":"7B"}]]}],["$","div","1",{"className":"spec","children":[["$","span",null,{"className":"spec-label","children":"Base"}],["$","span",null,{"className":"spec-value","children":"Qwen3-Omni"}]]}],["$","div","2",{"className":"spec","children":[["$","span",null,{"className":"spec-label","children":"Modalities"}],["$","span",null,{"className":"spec-value","children":"Text + Vision + Audio"}]]}],["$","div","3",{"className":"spec","children":[["$","span",null,{"className":"spec-label","children":"Type"}],["$","span",null,{"className":"spec-value","children":"Multimodal"}]]}]]}]
11:["$","p",null,{"className":"model-description","children":"Multimodal model based on Qwen3-Omni supporting text, vision, and audio understanding simultaneously. NOT Qwen2.5!"}]
12:["$","div",null,{"className":"model-formats","children":[["$","span","0",{"className":"format-tag","children":"SafeTensors"}]]}]
13:["$","div",null,{"className":"model-actions","children":[["$","a",null,{"href":"https://huggingface.co/zenlm/zen-omni","className":"btn btn-sm btn-primary","target":"_blank","rel":"noopener noreferrer","children":"ðŸ¤— HF"}],["$","a",null,{"href":"https://github.com/zenlm/zen-omni","className":"btn btn-sm btn-secondary","target":"_blank","rel":"noopener noreferrer","children":"ðŸ“¦ GitHub"}],["$","a",null,{"href":"https://github.com/zenlm/zen-omni/tree/main/docs","className":"btn btn-sm btn-secondary","target":"_blank","rel":"noopener noreferrer","children":"ðŸ“– Docs"}],["$","a",null,{"href":"/papers/zen-omni_whitepaper.pdf","className":"btn btn-sm btn-secondary","target":"_blank","rel":"noopener noreferrer","children":"ðŸ“„ Paper"}]]}]
14:["$","div",null,{"className":"model-card complete","children":[["$","div",null,{"className":"model-header","children":[["$","h3",null,{"children":"zen-coder"}],["$","span",null,{"className":"badge badge-complete","children":"Available"}]]}],["$","div",null,{"className":"model-specs","children":[["$","div","0",{"className":"spec","children":[["$","span",null,{"className":"spec-label","children":"Parameters"}],["$","span",null,{"className":"spec-value","children":"14B"}]]}],["$","div","1",{"className":"spec","children":[["$","span",null,{"className":"spec-label","children":"Base"}],["$","span",null,{"className":"spec-value","children":"Qwen3-Coder-14B"}]]}],["$","div","2",{"className":"spec","children":[["$","span",null,{"className":"spec-label","children":"Context"}],["$","span",null,{"className":"spec-value","children":"128K tokens"}]]}],["$","div","3",{"className":"spec","children":[["$","span",null,{"className":"spec-label","children":"Focus"}],["$","span",null,{"className":"spec-value","children":"Code Generation"}]]}]]}],["$","p",null,{"className":"model-description","children":"Specialized for code generation, debugging, and software engineering tasks. Supports 100+ programming languages with extended context."}],["$","div",null,{"className":"model-formats","children":[["$","span","0",{"className":"format-tag","children":"SafeTensors"}],["$","span","1",{"className":"format-tag","children":"GGUF"}],["$","span","2",{"className":"format-tag","children":"MLX"}]]}],["$","div",null,{"className":"model-actions","children":[["$","a",null,{"href":"https://huggingface.co/zenlm/zen-coder","className":"btn btn-sm btn-primary","target":"_blank","rel":"noopener noreferrer","children":"ðŸ¤— HF"}],["$","a",null,{"href":"https://github.com/zenlm/zen-coder","className":"btn btn-sm btn-secondary","target":"_blank","rel":"noopener noreferrer","children":"ðŸ“¦ GitHub"}],"$undefined","$undefined"]}]]}]
15:["$","div",null,{"className":"model-card complete","children":[["$","div",null,{"className":"model-header","children":[["$","h3",null,{"children":"zen-next"}],["$","span",null,{"className":"badge badge-complete","children":"Available"}]]}],["$","div",null,{"className":"model-specs","children":[["$","div","0",{"className":"spec","children":[["$","span",null,{"className":"spec-label","children":"Parameters"}],["$","span",null,{"className":"spec-value","children":"32B"}]]}],["$","div","1",{"className":"spec","children":[["$","span",null,{"className":"spec-label","children":"Base"}],["$","span",null,{"className":"spec-value","children":"Qwen3-32B"}]]}],["$","div","2",{"className":"spec","children":[["$","span",null,{"className":"spec-label","children":"Context"}],["$","span",null,{"className":"spec-value","children":"32K tokens"}]]}],["$","div","3",{"className":"spec","children":[["$","span",null,{"className":"spec-label","children":"Focus"}],["$","span",null,{"className":"spec-value","children":"Frontier"}]]}]]}],["$","p",null,{"className":"model-description","children":"Our flagship model pushing the boundaries of performance and capability. For the most demanding applications requiring maximum intelligence."}],["$","div",null,{"className":"model-formats","children":[["$","span","0",{"className":"format-tag","children":"SafeTensors"}],["$","span","1",{"className":"format-tag","children":"GGUF"}]]}],["$","div",null,{"className":"model-actions","children":["$undefined",["$","a",null,{"href":"https://github.com/zenlm/zen-next","className":"btn btn-sm btn-secondary","target":"_blank","rel":"noopener noreferrer","children":"ðŸ“¦ GitHub"}],"$undefined","$undefined"]}]]}]
16:["$","span",null,{"className":"spec-value","children":"Qwen-Image"}]
17:["$","div","2",{"className":"spec","children":[["$","span",null,{"className":"spec-label","children":"Variants"}],["$","span",null,{"className":"spec-value","children":"Base, Edit"}]]}]
18:["$","div","3",{"className":"spec","children":[["$","span",null,{"className":"spec-label","children":"Focus"}],["$","span",null,{"className":"spec-value","children":"Image Generation"}]]}]
19:["$","p",null,{"className":"model-description","children":"High-quality image generation from text descriptions. zen-artist-edit provides advanced image editing capabilities with natural language instructions."}]
1a:["$","div",null,{"className":"model-formats","children":[["$","span","0",{"className":"format-tag","children":"SafeTensors"}],["$","span","1",{"className":"format-tag","children":"Diffusers"}]]}]
1b:["$","div",null,{"className":"model-actions","children":["$undefined",["$","a",null,{"href":"https://github.com/zenlm/zen-artist","className":"btn btn-sm btn-secondary","target":"_blank","rel":"noopener noreferrer","children":"ðŸ“¦ GitHub"}],"$undefined","$undefined"]}]
1c:["$","div",null,{"className":"model-card complete","children":[["$","div",null,{"className":"model-header","children":[["$","h3",null,{"children":"zen-video"}],["$","span",null,{"className":"badge badge-complete","children":"Available"}]]}],["$","div",null,{"className":"model-specs","children":[["$","div","0",{"className":"spec","children":[["$","span",null,{"className":"spec-label","children":"Type"}],["$","span",null,{"className":"spec-value","children":"Text-to-Video"}]]}],["$","div","1",{"className":"spec","children":[["$","span",null,{"className":"spec-label","children":"Base"}],["$","span",null,{"className":"spec-value","children":"HunyuanVideo"}]]}],["$","div","2",{"className":"spec","children":[["$","span",null,{"className":"spec-label","children":"Variants"}],["$","span",null,{"className":"spec-value","children":"T2V, I2V"}]]}],["$","div","3",{"className":"spec","children":[["$","span",null,{"className":"spec-label","children":"Focus"}],["$","span",null,{"className":"spec-value","children":"Video Generation"}]]}]]}],["$","p",null,{"className":"model-description","children":"State-of-the-art video generation from text descriptions. zen-video-i2v provides image-to-video generation with fine control over motion and dynamics."}],["$","div",null,{"className":"model-formats","children":[["$","span","0",{"className":"format-tag","children":"SafeTensors"}]]}],["$","div",null,{"className":"model-actions","children":["$undefined",["$","a",null,{"href":"https://github.com/zenlm/zen-video","className":"btn btn-sm btn-secondary","target":"_blank","rel":"noopener noreferrer","children":"ðŸ“¦ GitHub"}],"$undefined","$undefined"]}]]}]
1d:["$","div",null,{"className":"model-card complete","children":[["$","div",null,{"className":"model-header","children":[["$","h3",null,{"children":"zen-3d"}],["$","span",null,{"className":"badge badge-complete","children":"Available"}]]}],["$","div",null,{"className":"model-specs","children":[["$","div","0",{"className":"spec","children":[["$","span",null,{"className":"spec-label","children":"Type"}],["$","span",null,{"className":"spec-value","children":"3D Generation"}]]}],["$","div","1",{"className":"spec","children":[["$","span",null,{"className":"spec-label","children":"Input"}],["$","span",null,{"className":"spec-value","children":"Text, Image, Point Cloud"}]]}],["$","div","2",{"className":"spec","children":[["$","span",null,{"className":"spec-label","children":"Output"}],["$","span",null,{"className":"spec-value","children":"3D Meshes"}]]}],["$","div","3",{"className":"spec","children":[["$","span",null,{"className":"spec-label","children":"Focus"}],["$","span",null,{"className":"spec-value","children":"3D Assets"}]]}]]}],["$","p",null,{"className":"model-description","children":"Generate high-quality 3D models from various input modalities. Perfect for game development, AR/VR, and 3D content creation."}],["$","div",null,{"className":"model-formats","children":[["$","span","0",{"className":"format-tag","children":"SafeTensors"}]]}],["$","div",null,{"className":"model-actions","children":["$undefined",["$","a",null,{"href":"https://github.com/zenlm/zen-3d","className":"btn btn-sm btn-secondary","target":"_blank","rel":"noopener noreferrer","children":"ðŸ“¦ GitHub"}],"$undefined","$undefined"]}]]}]
1e:["$","div",null,{"className":"model-card complete","children":[["$","div",null,{"className":"model-header","children":[["$","h3",null,{"children":"zen-musician"}],["$","span",null,{"className":"badge badge-complete","children":"Available"}]]}],["$","div",null,{"className":"model-specs","children":[["$","div","0",{"className":"spec","children":[["$","span",null,{"className":"spec-label","children":"Type"}],["$","span",null,{"className":"spec-value","children":"Music Generation"}]]}],["$","div","1",{"className":"spec","children":[["$","span",null,{"className":"spec-label","children":"Input"}],["$","span",null,{"className":"spec-value","children":"Text, Audio"}]]}],["$","div","2",{"className":"spec","children":[["$","span",null,{"className":"spec-label","children":"Output"}],["$","span",null,{"className":"spec-value","children":"Music, Audio"}]]}],["$","div","3",{"className":"spec","children":[["$","span",null,{"className":"spec-label","children":"Focus"}],["$","span",null,{"className":"spec-value","children":"Music Creation"}]]}]]}],["$","p",null,{"className":"model-description","children":"Generate high-quality music from text descriptions or audio samples. Supports multiple genres, instruments, and musical styles."}],["$","div",null,{"className":"model-formats","children":[["$","span","0",{"className":"format-tag","children":"SafeTensors"}]]}],["$","div",null,{"className":"model-actions","children":["$undefined",["$","a",null,{"href":"https://github.com/zenlm/zen-musician","className":"btn btn-sm btn-secondary","target":"_blank","rel":"noopener noreferrer","children":"ðŸ“¦ GitHub"}],"$undefined","$undefined"]}]]}]
24:[["$","meta","0",{"charSet":"utf-8"}],["$","meta","1",{"name":"viewport","content":"width=device-width, initial-scale=1"}]]
20:null
22:{"metadata":[["$","title","0",{"children":"Zen LM Models - Complete Model Family"}],["$","meta","1",{"name":"description","content":"Complete collection of Zen Language Models - from nano to next-gen, language to multimodal"}],["$","meta","2",{"name":"keywords","content":"AI, LLM, Agentic AI, Code Generation, Zen Coder, Multimodal, Open Source, Machine Learning"}]],"error":null,"digest":"$undefined"}
27:"$22:metadata"
